{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "from __future__ import print_function\n",
    "from apiclient.discovery import build\n",
    "from apiclient.http import MediaFileUpload\n",
    "from httplib2 import Http\n",
    "from oauth2client import file as oauth_file, client, tools\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = 'https://www.googleapis.com/auth/drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_folder_id = '1bxUFafpwtUZT2CMOOPjosFhN9FTUBN4l'\n",
    "tmp_data_dir = 'tmp'\n",
    "data_dir = 'data'\n",
    "minutes = 60\n",
    "seconds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drive_service():\n",
    "    store = oauth_file.Storage('token.json')\n",
    "    creds = store.get()\n",
    "    if not creds or creds.invalid:\n",
    "        flow = client.flow_from_clientsecrets('credentials.json', SCOPES)\n",
    "        creds = tools.run_flow(flow, store)\n",
    "    return build('drive', 'v3', http=creds.authorize(Http()))\n",
    "\n",
    "def mkdir_GDrive(folder_name):\n",
    "    drive_service = get_drive_service()\n",
    "    \n",
    "    file_metadata = {\n",
    "        'name': folder_name,\n",
    "        'mimeType': 'application/vnd.google-apps.folder'\n",
    "    }\n",
    "    file = drive_service.files().create(body=file_metadata,\n",
    "                                        fields='id').execute()\n",
    "    return file.get('id')\n",
    "\n",
    "def upload_GDrive(local_filepath, remote_filename, remote_folder_id=None, mimetype='text/plain'):\n",
    "    drive_service = get_drive_service()\n",
    "    \n",
    "    file_metadata = {'name': remote_filepath}\n",
    "    if not remote_folder_id==None: file_metadata['parents'] = [remote_folder_id]\n",
    "    media = MediaFileUpload(local_filepath, mimetype=mimetype, resumable=True)\n",
    "    file = drive_service.files().create(body=file_metadata, media_body=media).execute()\n",
    "    \n",
    "def csv_to_gzip():\n",
    "    # Convert csv files from tmp data into MultiIndex DataFrame, then save to gzip\n",
    "    df=None\n",
    "    timestamps = []\n",
    "    for filename in os.listdir(tmp_data_dir):\n",
    "        if filename[-4:] == '.csv':\n",
    "            timestamps.append(filename[:-4])\n",
    "            tmp_df = pd.read_csv(os.path.join(tmp_data_dir, filename), index_col=0)\n",
    "            if df is None:\n",
    "                df=tmp_df\n",
    "            else:\n",
    "                df = df.append(tmp_df)\n",
    "\n",
    "    index = [np.repeat(timestamps,3),\n",
    "             np.array(df.index)]\n",
    "    columns = np.array(df.columns)\n",
    "    df = pd.DataFrame(df.values, index=index, columns=columns)\n",
    "\n",
    "    filename = '{}.gz'.format(time.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
    "    df.to_csv(os.path.join(data_dir, filename), compression='gzip')\n",
    "    \n",
    "    # Empty tmp folder\n",
    "    #shutil.rmtree(tmp_data_dir)\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1bxUFafpwtUZT2CMOOPjosFhN9FTUBN4l'"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make new folder in Google Drive\n",
    "#mkdir_GDrive('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfL Unified API credentials\n",
    "bikepoint_endpoint = 'https://api.tfl.gov.uk/BikePoint'\n",
    "api_key = '92d100947363f402b8799976aea7fb43'\n",
    "api_id = 'fffcdfe2'\n",
    "payload = {'app_id': api_id, 'app_key': api_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_loop_wait_time = 30*seconds\n",
    "write_loop_wait_time = 5*seconds\n",
    "\n",
    "if not os.path.isdir(tmp_data_dir):\n",
    "    os.mkdir(tmp_data_dir)\n",
    "\n",
    "### Infinite Loop ###\n",
    "while True:\n",
    "    \n",
    "    ### Upload Loop ###\n",
    "    # Upload to Google Drive after X minute(s)\n",
    "    pbar = tqdm(total=(upload_loop_wait_time//write_loop_wait_time))\n",
    "    upload_loop_start_time = time.time() # in secs\n",
    "    while (time.time() - upload_loop_start_time) <= upload_loop_wait_time:\n",
    "        # Start time\n",
    "        write_loop_start_time = time.time() # in secs\n",
    "\n",
    "        # Request new bikepoint data\n",
    "        bikepoints = requests.get(bikepoint_endpoint, params=payload).json()\n",
    "\n",
    "        # Extract just data relating to bike availability\n",
    "        bikepoint_dict = {}\n",
    "        for bikepoint in bikepoints:\n",
    "            bikepoint_dict[bikepoint['id']] = {item['key']:item['value'] \n",
    "                                               for item in bikepoint['additionalProperties'] \n",
    "                                               if item['key'][:2]=='Nb'}\n",
    "        bikepoint_df = pd.DataFrame(bikepoint_dict)\n",
    "\n",
    "        # Save to file\n",
    "        bikepoint_df.to_csv(\n",
    "            os.path.join(tmp_data_dir, \n",
    "            '{}.csv'.format(time.strftime(\"%Y-%m-%d_%H:%M:%S\")))\n",
    "        )\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "        ### Write Loop ###\n",
    "        while (time.time() - write_loop_start_time) <= write_loop_wait_time:\n",
    "            time.sleep(0.1) #  check every 0.1 secs\n",
    "            \n",
    "    # Condense tmp csv files into gzip\n",
    "    filename = csv_to_gzip()\n",
    "    # Save to Google Drive\n",
    "    local_filepath = os.path.join(data_dir, filename)\n",
    "    remote_filename = filename\n",
    "    upload_GDrive(local_filepath, remote_filename, remote_folder_id=remote_folder_id, \n",
    "                  mimetype='application/zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a MultiIndex DataFrame from a CSV\n",
    "#tmp = pd.read_csv(os.path.join(data_dir, '2018-08-07_17:35:30.csv.gz'), \n",
    "#                  compression='gzip', index_col=[0,1])\n",
    "\n",
    "# Accessing rows in a MultiIndex DataFrame\n",
    "#df.loc['2018-08-07_15:31:58', 'NbBikes']\n",
    "#df.loc['2018-08-07_15:31:58']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
